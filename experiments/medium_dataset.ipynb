{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/esm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:      (10000, 6), pos-ratio=0.500\n",
      "Validation set: (2000, 6),   pos-ratio=0.500\n",
      "Test1 set:      (2000, 6), pos-ratio=0.500\n",
      "Test2 set:      (10000, 6), pos-ratio=0.090\n",
      "\n",
      "All datasets successfully saved to 'data/small_set'\n"
     ]
    }
   ],
   "source": [
    "# 1) Load the four “full” splits\n",
    "train_full  = pd.read_csv('../data/full_dataset/train_data.csv')\n",
    "val_full    = pd.read_csv('../data/full_dataset/validation_data.csv')\n",
    "test1_full  = pd.read_csv('../data/full_dataset/test1_data.csv')\n",
    "test2_full  = pd.read_csv('../data/full_dataset/test2_data.csv')\n",
    "\n",
    "# 2) Build a 10 000-example train set, 50/50\n",
    "n_train = 10000\n",
    "n_pos_train = n_neg_train = n_train // 2\n",
    "pos_train = train_full[train_full['isInteraction'] == 1]\\\n",
    "              .sample(n=n_pos_train, random_state=42)\n",
    "neg_train = train_full[train_full['isInteraction'] == 0]\\\n",
    "              .sample(n=n_neg_train, random_state=42)\n",
    "train_data = pd.concat([pos_train, neg_train])\\\n",
    "               .sample(frac=1, random_state=43)\\\n",
    "               .reset_index(drop=True)\n",
    "\n",
    "# 3) Build a “reasonable” validation set: 2 000 examples, 50/50\n",
    "n_val = 2000\n",
    "n_pos_val = n_neg_val = n_val // 2\n",
    "pos_val = val_full[val_full['isInteraction'] == 1]\\\n",
    "            .sample(n=n_pos_val, random_state=44)\n",
    "neg_val = val_full[val_full['isInteraction'] == 0]\\\n",
    "            .sample(n=n_neg_val, random_state=44)\n",
    "cv_data = pd.concat([pos_val, neg_val])\\\n",
    "            .sample(frac=1, random_state=45)\\\n",
    "            .reset_index(drop=True)\n",
    "cv_data['trainTest'] = 'validation'\n",
    "\n",
    "# 4) Build test1: 2 000 examples, 50/50\n",
    "n_test1 = 2000\n",
    "n_pos_test1 = n_neg_test1 = n_test1 // 2\n",
    "pos_test1 = test1_full[test1_full['isInteraction'] == 1]\\\n",
    "              .sample(n=n_pos_test1, random_state=46)\n",
    "neg_test1 = test1_full[test1_full['isInteraction'] == 0]\\\n",
    "              .sample(n=n_neg_test1, random_state=46)\n",
    "test1_data = pd.concat([pos_test1, neg_test1])\\\n",
    "               .sample(frac=1, random_state=47)\\\n",
    "               .reset_index(drop=True)\n",
    "\n",
    "# 5) Build test2: 10 000 examples, ~9% pos, ~91% neg\n",
    "n_test2 = 10000\n",
    "n_pos_test2 = int(n_test2 * 0.09)\n",
    "n_neg_test2 = n_test2 - n_pos_test2\n",
    "pos_test2 = test2_full[test2_full['isInteraction'] == 1]\\\n",
    "              .sample(n=n_pos_test2, random_state=48)\n",
    "neg_test2 = test2_full[test2_full['isInteraction'] == 0]\\\n",
    "              .sample(n=n_neg_test2, random_state=48)\n",
    "test2_data = pd.concat([pos_test2, neg_test2])\\\n",
    "               .sample(frac=1, random_state=49)\\\n",
    "               .reset_index(drop=True)\n",
    "\n",
    "# 6) Print class‐balance stats\n",
    "print(f\"Train set:      {train_data.shape}, pos-ratio={train_data['isInteraction'].mean():.3f}\")\n",
    "print(f\"Validation set: {cv_data.shape},   pos-ratio={cv_data['isInteraction'].mean():.3f}\")\n",
    "print(f\"Test1 set:      {test1_data.shape}, pos-ratio={test1_data['isInteraction'].mean():.3f}\")\n",
    "print(f\"Test2 set:      {test2_data.shape}, pos-ratio={test2_data['isInteraction'].mean():.3f}\")\n",
    "\n",
    "# 7) Save to disk\n",
    "out_dir = '../data/medium_set'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for df, name in [\n",
    "    (train_data, 'train_data'),\n",
    "    (cv_data,    'validation_data'),\n",
    "    (test1_data, 'test1_data'),\n",
    "    (test2_data, 'test2_data'),\n",
    "]:\n",
    "    df.to_pickle(f'{out_dir}/{name}.pkl')\n",
    "    df.to_csv(f'{out_dir}/{name}.csv', index=False)\n",
    "\n",
    "print(\"\\nAll datasets successfully saved to 'data/medium_set'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprotID_A</th>\n",
       "      <th>uniprotID_B</th>\n",
       "      <th>isInteraction</th>\n",
       "      <th>trainTest</th>\n",
       "      <th>sequence_A</th>\n",
       "      <th>sequence_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q92529</td>\n",
       "      <td>Q9H6L4</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>MLPRTKYNRFRNDSVTSVDDLLHSLSVSGGGGKVSAARATPAAAPY...</td>\n",
       "      <td>MAQKPKVDPHVGRLGYLQALVTEFQETQSQDAKEQVLANLANFAYD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P09326</td>\n",
       "      <td>Q02446</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>MCSRGWDSCLALELLLLPLSLLVTSIQGHLVHMTVVSGSNVTLNIS...</td>\n",
       "      <td>MSDQKKEEEEEAAAAAAMATEGGKTSEPENNNKKPKTSGSQDSQPS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q4V328</td>\n",
       "      <td>Q9H2H9</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>MAQALSEEEFQRMQAQLLELRTNNYQLSDELRKNGVELTSLRQKVA...</td>\n",
       "      <td>MMHFKSGLELTELQNMTVPEDDNISNDSNDFTEVENGQINSKFISD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O95835</td>\n",
       "      <td>Q9NTJ5</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>MKRSEKPEGYRQMRPKTFPASNYTVSSRQMLQEIRESLRNLSKPSD...</td>\n",
       "      <td>MATAAYEQLKLHITPEKFYVEACDDGADDVLTIDRVSTEVTLAVKK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O95125</td>\n",
       "      <td>Q96JC9</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>MATAVEPEDQDLWEEEGILMVKLEDDFTCRPESVLQRDDPVLETSH...</td>\n",
       "      <td>MNGTANPLLDREEHCLRLGESFEKRPRASFHTIRYDFKPASIDTSC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>P78310</td>\n",
       "      <td>Q13094</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>MALLLCFVLLCGVVDFARSLSITTPEEMIEKAKGETAYLPCKFTLS...</td>\n",
       "      <td>MALRNVPFRSEVLGWDPDSLADYFKKLNYKDCEKAVKKYHIDGARF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Q5T7W7</td>\n",
       "      <td>Q9Y2D8</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>MPSSTSPDQGDDLENCILRFSDLDLKDMSLINPSSSLKAELDGSTK...</td>\n",
       "      <td>MGDWMTVTDPGLSSESKTISQYTSETKMSPSSLYSQQVLCSSIPLS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Q3KNW5</td>\n",
       "      <td>Q8WXI8</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>MRANCSSSSACPANSSEEELPVGLEVHGNLELVFTVVSTVMMGLLM...</td>\n",
       "      <td>MGLEKPQSKLEGGMHPQLIPSVIAVVFILLLSVCFIASCLVTHHNF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Q9UIG4</td>\n",
       "      <td>Q9Y224</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>MILNWKLLGILVLCLHTRGISGSEGHPSHPPAEDREEAGSPTLPQG...</td>\n",
       "      <td>MFRRKLTALDYHNPAGFNCKDETEFRNFIVWLEDQKIRHYKIEDRG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>O00560</td>\n",
       "      <td>Q5JR59</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>MSLYPSLEDLKVDKVIQAQTAFSANPANPAILSEASAPIPHDGNLY...</td>\n",
       "      <td>MSVPVAPKKSCYTQLRDNRNAARNNNESILSLGDTNANQIMLEVSS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uniprotID_A uniprotID_B  isInteraction trainTest  \\\n",
       "0         Q92529      Q9H6L4              0     train   \n",
       "1         P09326      Q02446              0     train   \n",
       "2         Q4V328      Q9H2H9              0     train   \n",
       "3         O95835      Q9NTJ5              0     train   \n",
       "4         O95125      Q96JC9              1     train   \n",
       "...          ...         ...            ...       ...   \n",
       "9995      P78310      Q13094              0     train   \n",
       "9996      Q5T7W7      Q9Y2D8              1     train   \n",
       "9997      Q3KNW5      Q8WXI8              0     train   \n",
       "9998      Q9UIG4      Q9Y224              1     train   \n",
       "9999      O00560      Q5JR59              1     train   \n",
       "\n",
       "                                             sequence_A  \\\n",
       "0     MLPRTKYNRFRNDSVTSVDDLLHSLSVSGGGGKVSAARATPAAAPY...   \n",
       "1     MCSRGWDSCLALELLLLPLSLLVTSIQGHLVHMTVVSGSNVTLNIS...   \n",
       "2     MAQALSEEEFQRMQAQLLELRTNNYQLSDELRKNGVELTSLRQKVA...   \n",
       "3     MKRSEKPEGYRQMRPKTFPASNYTVSSRQMLQEIRESLRNLSKPSD...   \n",
       "4     MATAVEPEDQDLWEEEGILMVKLEDDFTCRPESVLQRDDPVLETSH...   \n",
       "...                                                 ...   \n",
       "9995  MALLLCFVLLCGVVDFARSLSITTPEEMIEKAKGETAYLPCKFTLS...   \n",
       "9996  MPSSTSPDQGDDLENCILRFSDLDLKDMSLINPSSSLKAELDGSTK...   \n",
       "9997  MRANCSSSSACPANSSEEELPVGLEVHGNLELVFTVVSTVMMGLLM...   \n",
       "9998  MILNWKLLGILVLCLHTRGISGSEGHPSHPPAEDREEAGSPTLPQG...   \n",
       "9999  MSLYPSLEDLKVDKVIQAQTAFSANPANPAILSEASAPIPHDGNLY...   \n",
       "\n",
       "                                             sequence_B  \n",
       "0     MAQKPKVDPHVGRLGYLQALVTEFQETQSQDAKEQVLANLANFAYD...  \n",
       "1     MSDQKKEEEEEAAAAAAMATEGGKTSEPENNNKKPKTSGSQDSQPS...  \n",
       "2     MMHFKSGLELTELQNMTVPEDDNISNDSNDFTEVENGQINSKFISD...  \n",
       "3     MATAAYEQLKLHITPEKFYVEACDDGADDVLTIDRVSTEVTLAVKK...  \n",
       "4     MNGTANPLLDREEHCLRLGESFEKRPRASFHTIRYDFKPASIDTSC...  \n",
       "...                                                 ...  \n",
       "9995  MALRNVPFRSEVLGWDPDSLADYFKKLNYKDCEKAVKKYHIDGARF...  \n",
       "9996  MGDWMTVTDPGLSSESKTISQYTSETKMSPSSLYSQQVLCSSIPLS...  \n",
       "9997  MGLEKPQSKLEGGMHPQLIPSVIAVVFILLLSVCFIASCLVTHHNF...  \n",
       "9998  MFRRKLTALDYHNPAGFNCKDETEFRNFIVWLEDQKIRHYKIEDRG...  \n",
       "9999  MSVPVAPKKSCYTQLRDNRNAARNNNESILSLGDTNANQIMLEVSS...  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode proteins using ESM C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 95869.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESM-C] Loaded locally on cuda\n"
     ]
    }
   ],
   "source": [
    "from esm.models.esmc import ESMC\n",
    "from esm.sdk.api import ESMProtein, LogitsConfig\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ESMC.from_pretrained(\"esmc_300m\").to(device)\n",
    "print(f\"[ESM-C] Loaded locally on {device}\")\n",
    "model_type = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_protein_embedding(sequence):\n",
    "    \"\"\"\n",
    "    Get protein embedding for a given sequence using the loaded ESM model.\n",
    "    Optimized with torch.no_grad() for inference.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():  # Ensures no gradients are computed for model operations\n",
    "        protein = ESMProtein(sequence=sequence)\n",
    "        protein_tensor = model.encode(protein)  # Model inference step\n",
    "        logits_output = model.logits(           # Model inference step\n",
    "            protein_tensor,\n",
    "            LogitsConfig(sequence=True, return_embeddings=True)\n",
    "        )\n",
    "        # Get the per-protein representation by mean-pooling across sequence length\n",
    "        embedding = logits_output.embeddings\n",
    "    return embedding.cpu().numpy() # Move to CPU and convert to NumPy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm # Use tqdm.auto for better notebook compatibility\n",
    "\n",
    "def process_dataset(df, sample_size=None):\n",
    "    \"\"\"Process dataset to add embeddings for both protein sequences.\n",
    "    This function calls the optimized get_protein_embedding.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with protein sequences in 'sequence_A' and 'sequence_B' columns.\n",
    "        sample_size: Optional, number of examples to process (for testing).\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    if sample_size is not None and 0 < sample_size < len(df):\n",
    "        # Ensure sample_size is valid if provided\n",
    "        result_df = df.sample(n=sample_size, random_state=42).copy()\n",
    "        print(f\"Processing a sample of {len(result_df)} examples.\")\n",
    "    elif sample_size is not None and sample_size >= len(df):\n",
    "        print(f\"sample_size ({sample_size}) is >= DataFrame length ({len(df)}). Processing all examples.\")\n",
    "        result_df = df.copy()\n",
    "    else: # sample_size is None or 0 or invalid\n",
    "        result_df = df.copy()\n",
    "        print(f\"Processing all {len(result_df)} examples.\")\n",
    "\n",
    "    embeddings_A = []\n",
    "    embeddings_B = []\n",
    "\n",
    "    # Iterate through the selected DataFrame rows\n",
    "    # Ensure 'sequence_A' and 'sequence_B' columns exist\n",
    "    if 'sequence_A' not in result_df.columns or 'sequence_B' not in result_df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'sequence_A' and 'sequence_B' columns.\")\n",
    "\n",
    "    for i, row in tqdm(result_df.iterrows(), total=len(result_df), desc=\"Encoding proteins\"):\n",
    "        # Get embeddings for protein A and B using the optimized function\n",
    "        embedding_A = get_protein_embedding(row['sequence_A'])\n",
    "        embedding_B = get_protein_embedding(row['sequence_B'])\n",
    "\n",
    "        embeddings_A.append(embedding_A)\n",
    "        embeddings_B.append(embedding_B)\n",
    "\n",
    "    # Store the embeddings as new columns in the DataFrame\n",
    "    result_df['embedding_A'] = embeddings_A\n",
    "    result_df['embedding_B'] = embeddings_B\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding train split ---\n",
      "Processing all 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding proteins: 100%|██████████| 10000/10000 [10:24<00:00, 16.00it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../data/medium_set/embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/medium_set/train_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m train_data_with_embeddings \u001b[38;5;241m=\u001b[39m process_dataset(df)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_data_with_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/medium_set/embeddings/train_data_with_embeddings.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../data/medium_set/embeddings'"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Encoding train split ---\")\n",
    "df = pd.read_csv(\"../data/medium_set/train_data.csv\", index_col=0)\n",
    "train_data_with_embeddings = process_dataset(df)\n",
    "train_data_with_embeddings.to_csv('../data/medium_set/embeddings/train_data_with_embeddings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_embeddings.to_csv('../data/medium_set/embeddings/train_data_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding validation split ---\n",
      "Processing all 2000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding proteins: 100%|██████████| 2000/2000 [02:01<00:00, 16.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Validation split\n",
    "if 'cuda' in str(device):\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"\\n--- Encoding validation split ---\")\n",
    "df = pd.read_csv(\"../data/medium_set/validation_data.csv\", index_col=0)\n",
    "val_data_with_embeddings = process_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_with_embeddings.to_csv('../data/medium_set/embeddings/validation_data_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding test1 split ---\n",
      "Processing all 2000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding proteins: 100%|██████████| 2000/2000 [02:23<00:00, 13.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Test1 split\n",
    "if 'cuda' in str(device):\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"\\n--- Encoding test1 split ---\")\n",
    "df = pd.read_csv(\"../data/medium_set/test1_data.csv\", index_col=0)\n",
    "test1_data_with_embeddings = process_dataset(df)\n",
    "test1_data_with_embeddings.to_csv('../data/medium_set/embeddings/test1_data_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(df, sample_size=None, device_to_check=None): # Added device_to_check\n",
    "    \"\"\"Process dataset to add embeddings for both protein sequences,\n",
    "    with GPU cache clearing to help manage memory.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with protein sequences in 'sequence_A' and 'sequence_B' columns.\n",
    "        sample_size: Optional, number of examples to process (for testing).\n",
    "        device_to_check: The torch.device being used (e.g., global 'device').\n",
    "                         This is needed to conditionally empty CUDA cache.\n",
    "    \"\"\"\n",
    "    if device_to_check is None:\n",
    "        # Fallback to a globally defined 'device' if not passed, or raise an error\n",
    "        # For this example, let's try to use a global 'device' if not provided,\n",
    "        # but passing it explicitly is better practice.\n",
    "        try:\n",
    "            # This line assumes 'device' is a global variable.\n",
    "            # If not, this will cause a NameError.\n",
    "            # It's better to require 'device_to_check' to be passed.\n",
    "            # For robustness, we should handle if 'device' isn't globally defined.\n",
    "            # Consider raising an error if device_to_check is None and no global 'device' is found.\n",
    "            # For now, let's assume 'device' is available if device_to_check is None\n",
    "            global device # This declares intent to use a global variable named 'device'\n",
    "            current_device_str = str(device)\n",
    "            if 'cuda' not in current_device_str:\n",
    "                 print(\"Warning: device_to_check not provided, and global 'device' is not CUDA. CUDA cache will not be cleared.\")\n",
    "        except NameError:\n",
    "            print(\"Warning: 'device_to_check' not provided and global 'device' not found. GPU cache clearing will be skipped.\")\n",
    "            current_device_str = \"cpu\" # Assume CPU if device is unknown\n",
    "    else:\n",
    "        current_device_str = str(device_to_check)\n",
    "\n",
    "\n",
    "    # --- DataFrame preparation (sampling) ---\n",
    "    if sample_size is not None and 0 < sample_size < len(df):\n",
    "        result_df = df.sample(n=sample_size, random_state=42).copy()\n",
    "        print(f\"Processing a sample of {len(result_df)} examples.\")\n",
    "    elif sample_size is not None and sample_size >= len(df):\n",
    "        print(f\"sample_size ({sample_size}) is >= DataFrame length ({len(df)}). Processing all examples.\")\n",
    "        result_df = df.copy()\n",
    "    else: # sample_size is None or 0 or invalid\n",
    "        result_df = df.copy()\n",
    "        print(f\"Processing all {len(result_df)} examples.\")\n",
    "\n",
    "    embeddings_A = []\n",
    "    embeddings_B = []\n",
    "\n",
    "    if 'sequence_A' not in result_df.columns or 'sequence_B' not in result_df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'sequence_A' and 'sequence_B' columns.\")\n",
    "\n",
    "    # --- Main processing loop ---\n",
    "    for i, row in tqdm(result_df.iterrows(), total=len(result_df), desc=\"Encoding proteins\"):\n",
    "        embedding_A_val = None\n",
    "        embedding_B_val = None\n",
    "        try:\n",
    "            # Get embeddings for protein A and B.\n",
    "            # Crucially, get_protein_embedding should use `torch.no_grad()` internally\n",
    "            # and return embeddings on the CPU (e.g., as NumPy arrays).\n",
    "            embedding_A_val = get_protein_embedding(row['sequence_A'])\n",
    "            embedding_B_val = get_protein_embedding(row['sequence_B'])\n",
    "\n",
    "        except Exception as e:\n",
    "            row_identifier = row.name if hasattr(row, 'name') and row.name is not None else f\"at numerical index {i}\"\n",
    "            print(f\"Error getting embedding for row {row_identifier}: {e}\")\n",
    "            # Embeddings will remain None and be appended as such.\n",
    "\n",
    "        finally:\n",
    "            embeddings_A.append(embedding_A_val)\n",
    "            embeddings_B.append(embedding_B_val)\n",
    "\n",
    "            # --- GPU Memory Optimization ---\n",
    "            # If running on GPU, clear the CUDA cache after processing each pair.\n",
    "            # This helps release memory that PyTorch's allocator might be holding onto\n",
    "            # but isn't actively used by tensors still in scope.\n",
    "            # This does NOT free memory of tensors that are still referenced.\n",
    "            # Calling this can have a small performance overhead.\n",
    "            if 'cuda' in current_device_str:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Store embeddings in DataFrame ---\n",
    "    result_df['embedding_A'] = embeddings_A\n",
    "    result_df['embedding_B'] = embeddings_B\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device from previous cells: cuda\n",
      "Operating on CUDA device: cuda. Clearing cache before processing test2 split.\n",
      "\n",
      "--- Encoding test2 split ---\n",
      "Loaded '../data/medium_set/test2_data.csv' with 10000 rows.\n",
      "Attempting to set memory fraction to 0.7 for GPU 0 (Timing is critical and likely too late here).\n",
      "Call to set_per_process_memory_fraction for GPU 0 completed.\n",
      "Processing all 10000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding proteins:  21%|██▏       | 2148/10000 [02:48<2:26:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting embedding for row Q8WZ42: CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 7.63 GiB of which 3.11 GiB is free. Including non-PyTorch memory, this process has 4.48 GiB memory in use. 5.34 GiB allowed; Of the allocated memory 2.80 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding proteins:  64%|██████▍   | 6433/10000 [07:54<40:58,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting embedding for row Q8WZ42: CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 7.63 GiB of which 3.11 GiB is free. Including non-PyTorch memory, this process has 4.48 GiB memory in use. 5.34 GiB allowed; Of the allocated memory 2.80 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding proteins: 100%|██████████| 10000/10000 [12:07<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data and saved embeddings to: ../data/medium_set/embeddings/test2_data_with_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current device from previous cells: {device if 'device' in locals() else 'device not defined yet'}\")\n",
    "\n",
    "if 'cuda' in str(device if 'device' in locals() else \"\"): # Check if the globally defined 'device' is CUDA\n",
    "    print(f\"Operating on CUDA device: {device}. Clearing cache before processing test2 split.\")\n",
    "    # This call to empty_cache() is a CUDA operation.\n",
    "    torch.cuda.empty_cache()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "\n",
    "print(\"\\n--- Encoding test2 split ---\")\n",
    "\n",
    "df_path = \"../data/medium_set/test2_data.csv\"\n",
    "df = pd.read_csv(df_path, index_col=0)\n",
    "print(f\"Loaded '{df_path}' with {len(df)} rows.\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    target_gpu_index_for_fraction = 0\n",
    "\n",
    "    print(f\"Attempting to set memory fraction to 0.7 for GPU {target_gpu_index_for_fraction} (Timing is critical and likely too late here).\")\n",
    "    torch.cuda.set_per_process_memory_fraction(0.7, device=target_gpu_index_for_fraction)\n",
    "    print(f\"Call to set_per_process_memory_fraction for GPU {target_gpu_index_for_fraction} completed.\")\n",
    "\n",
    "test2_data_with_embeddings = process_dataset(df)\n",
    "\n",
    "output_dir = '../data/medium_set/embeddings/'\n",
    "os.makedirs(output_dir, exist_ok=True) # Create the directory if it doesn't exist\n",
    "\n",
    "output_file_path = os.path.join(output_dir, 'test2_data_with_embeddings.csv')\n",
    "test2_data_with_embeddings.to_csv(output_file_path)\n",
    "print(f\"Processed data and saved embeddings to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprotID_B</th>\n",
       "      <th>isInteraction</th>\n",
       "      <th>trainTest</th>\n",
       "      <th>sequence_A</th>\n",
       "      <th>sequence_B</th>\n",
       "      <th>embedding_A</th>\n",
       "      <th>embedding_B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniprotID_A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q7Z3E5</th>\n",
       "      <td>Q9NWT1</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MGDILAHESELLGLVKEYLDFAEFEDTLKTFSKECKIKGKPLCKTV...</td>\n",
       "      <td>MELVAGCYEQVLFGFAVHPEPEACGDHEQWTLVADFTHHAHTASLS...</td>\n",
       "      <td>[[[0.004321804, -0.0029334754, -0.0005307504, ...</td>\n",
       "      <td>[[[0.0038145045, -0.009487958, -0.005827626, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O75083</th>\n",
       "      <td>Q9NXF1</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MPYEIKKVFASLPQVERGVSKIIGGDPKGNNFLYTNGKCVILRNID...</td>\n",
       "      <td>MTKKRKRQHDFQKVKLKVGKKKPKLQNATPTNFKTKTIHLPEQLKE...</td>\n",
       "      <td>[[[0.0065258597, -0.004280349, -0.003867632, -...</td>\n",
       "      <td>[[[0.0025960298, -0.010212678, -0.0012903364, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P0C5Z0</th>\n",
       "      <td>Q99880</td>\n",
       "      <td>1</td>\n",
       "      <td>test2</td>\n",
       "      <td>MPRRRRRRGSSGAGGRGRTCSRTVRAELSFSVSQVERSLREGHYAQ...</td>\n",
       "      <td>MPELAKSAPAPKKGSKKAVTKAQKKDGKKRKRSRKESYSVYVYKVL...</td>\n",
       "      <td>[[[0.000646868, -0.010081283, -0.0027380325, -...</td>\n",
       "      <td>[[[0.0011761499, -0.010396612, 0.0084419865, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1A5B4</th>\n",
       "      <td>Q9P2I0</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MQGEESLRILVEPEGDSFPLMEISTCETEASEQWDYVLVAQRHTQR...</td>\n",
       "      <td>MTSIIKLTTLSGVQEESALCYLLQVDEFRFLLDCGWDEHFSMDIID...</td>\n",
       "      <td>[[[0.0054729604, -0.0017307549, -0.0027065247,...</td>\n",
       "      <td>[[[0.0075324993, -0.0015358931, -0.0015184287,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P54368</th>\n",
       "      <td>Q13257</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MVKSSLQRILNSHCFAREKEGDKPSATIHASRTMPLLSLHSRGGSS...</td>\n",
       "      <td>MALQLSREQGITLRGSAEIVAEFFSFGINSILYQRGIYPSETFTRV...</td>\n",
       "      <td>[[[0.0017352804, 0.001303095, -6.672949e-05, -...</td>\n",
       "      <td>[[[0.007819155, 0.0008507449, 0.0038550901, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q8TC44</th>\n",
       "      <td>Q96F10</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MASATEDPVLERYFKGHKAAITSLDLSPNGKQLATASWDTFLMLWN...</td>\n",
       "      <td>MASVRIREAKEGDCGDILRLIRELAEFEKLSDQVKISEEALRADGF...</td>\n",
       "      <td>[[[0.0055712033, -0.004359013, 0.00023896691, ...</td>\n",
       "      <td>[[[-0.0010542598, -0.0024922702, 0.004882417, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P51965</th>\n",
       "      <td>Q00987</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MSDDDSRASTSSSSSSSSNQQTEKETNTPKKKESKVSMSKNSKLLS...</td>\n",
       "      <td>MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...</td>\n",
       "      <td>[[[0.0014971778, 0.0052266484, 0.006297158, -0...</td>\n",
       "      <td>[[[0.0017554004, 0.0024649953, 0.0026940322, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q12891</th>\n",
       "      <td>Q9Y3D2</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MRAGPGPTVTLALVLAVSWAMELKPTAPPIFTGRPFVVAWDVPTQD...</td>\n",
       "      <td>MARLLWLLRGLTLGTAPRRAVRGQAGGGGPGTGPGLGEAGSLATCE...</td>\n",
       "      <td>[[[0.0017791522, 0.0014129027, -0.00035532797,...</td>\n",
       "      <td>[[[-0.0035668905, -0.0049079894, 0.002008198, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O00198</th>\n",
       "      <td>O75964</td>\n",
       "      <td>0</td>\n",
       "      <td>test2</td>\n",
       "      <td>MCPCPLHRGRGPPAVCACSAGRLGLRSSAAQLTAARLKALGDELHQ...</td>\n",
       "      <td>MAQFVRNLVEKTPALVNAAVTYSKPRLATFWYYAKVELVPPTPAEI...</td>\n",
       "      <td>[[[0.0013422754, -0.0010929873, 0.0063630324, ...</td>\n",
       "      <td>[[[0.0016759296, -0.0018295981, -0.0023910706,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P40337</th>\n",
       "      <td>Q13939</td>\n",
       "      <td>1</td>\n",
       "      <td>test2</td>\n",
       "      <td>MPRRAENWDEAEVGAEEAGVEEYGPEEDGGEESGAEESGPEESGPE...</td>\n",
       "      <td>MKLEFTEKNYNSFVLQNLNRQRKRKEYWDMALSVDNHVFFAHRNVL...</td>\n",
       "      <td>[[[0.0057283486, 0.006382076, 0.0050483015, -0...</td>\n",
       "      <td>[[[0.00508935, -0.003714442, 0.004217586, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            uniprotID_B  isInteraction trainTest  \\\n",
       "uniprotID_A                                        \n",
       "Q7Z3E5           Q9NWT1              0     test2   \n",
       "O75083           Q9NXF1              0     test2   \n",
       "P0C5Z0           Q99880              1     test2   \n",
       "A1A5B4           Q9P2I0              0     test2   \n",
       "P54368           Q13257              0     test2   \n",
       "...                 ...            ...       ...   \n",
       "Q8TC44           Q96F10              0     test2   \n",
       "P51965           Q00987              0     test2   \n",
       "Q12891           Q9Y3D2              0     test2   \n",
       "O00198           O75964              0     test2   \n",
       "P40337           Q13939              1     test2   \n",
       "\n",
       "                                                    sequence_A  \\\n",
       "uniprotID_A                                                      \n",
       "Q7Z3E5       MGDILAHESELLGLVKEYLDFAEFEDTLKTFSKECKIKGKPLCKTV...   \n",
       "O75083       MPYEIKKVFASLPQVERGVSKIIGGDPKGNNFLYTNGKCVILRNID...   \n",
       "P0C5Z0       MPRRRRRRGSSGAGGRGRTCSRTVRAELSFSVSQVERSLREGHYAQ...   \n",
       "A1A5B4       MQGEESLRILVEPEGDSFPLMEISTCETEASEQWDYVLVAQRHTQR...   \n",
       "P54368       MVKSSLQRILNSHCFAREKEGDKPSATIHASRTMPLLSLHSRGGSS...   \n",
       "...                                                        ...   \n",
       "Q8TC44       MASATEDPVLERYFKGHKAAITSLDLSPNGKQLATASWDTFLMLWN...   \n",
       "P51965       MSDDDSRASTSSSSSSSSNQQTEKETNTPKKKESKVSMSKNSKLLS...   \n",
       "Q12891       MRAGPGPTVTLALVLAVSWAMELKPTAPPIFTGRPFVVAWDVPTQD...   \n",
       "O00198       MCPCPLHRGRGPPAVCACSAGRLGLRSSAAQLTAARLKALGDELHQ...   \n",
       "P40337       MPRRAENWDEAEVGAEEAGVEEYGPEEDGGEESGAEESGPEESGPE...   \n",
       "\n",
       "                                                    sequence_B  \\\n",
       "uniprotID_A                                                      \n",
       "Q7Z3E5       MELVAGCYEQVLFGFAVHPEPEACGDHEQWTLVADFTHHAHTASLS...   \n",
       "O75083       MTKKRKRQHDFQKVKLKVGKKKPKLQNATPTNFKTKTIHLPEQLKE...   \n",
       "P0C5Z0       MPELAKSAPAPKKGSKKAVTKAQKKDGKKRKRSRKESYSVYVYKVL...   \n",
       "A1A5B4       MTSIIKLTTLSGVQEESALCYLLQVDEFRFLLDCGWDEHFSMDIID...   \n",
       "P54368       MALQLSREQGITLRGSAEIVAEFFSFGINSILYQRGIYPSETFTRV...   \n",
       "...                                                        ...   \n",
       "Q8TC44       MASVRIREAKEGDCGDILRLIRELAEFEKLSDQVKISEEALRADGF...   \n",
       "P51965       MCNTNMSVPTDGAVTTSQIPASEQETLVRPKPLLLKLLKSVGAQKD...   \n",
       "Q12891       MARLLWLLRGLTLGTAPRRAVRGQAGGGGPGTGPGLGEAGSLATCE...   \n",
       "O00198       MAQFVRNLVEKTPALVNAAVTYSKPRLATFWYYAKVELVPPTPAEI...   \n",
       "P40337       MKLEFTEKNYNSFVLQNLNRQRKRKEYWDMALSVDNHVFFAHRNVL...   \n",
       "\n",
       "                                                   embedding_A  \\\n",
       "uniprotID_A                                                      \n",
       "Q7Z3E5       [[[0.004321804, -0.0029334754, -0.0005307504, ...   \n",
       "O75083       [[[0.0065258597, -0.004280349, -0.003867632, -...   \n",
       "P0C5Z0       [[[0.000646868, -0.010081283, -0.0027380325, -...   \n",
       "A1A5B4       [[[0.0054729604, -0.0017307549, -0.0027065247,...   \n",
       "P54368       [[[0.0017352804, 0.001303095, -6.672949e-05, -...   \n",
       "...                                                        ...   \n",
       "Q8TC44       [[[0.0055712033, -0.004359013, 0.00023896691, ...   \n",
       "P51965       [[[0.0014971778, 0.0052266484, 0.006297158, -0...   \n",
       "Q12891       [[[0.0017791522, 0.0014129027, -0.00035532797,...   \n",
       "O00198       [[[0.0013422754, -0.0010929873, 0.0063630324, ...   \n",
       "P40337       [[[0.0057283486, 0.006382076, 0.0050483015, -0...   \n",
       "\n",
       "                                                   embedding_B  \n",
       "uniprotID_A                                                     \n",
       "Q7Z3E5       [[[0.0038145045, -0.009487958, -0.005827626, -...  \n",
       "O75083       [[[0.0025960298, -0.010212678, -0.0012903364, ...  \n",
       "P0C5Z0       [[[0.0011761499, -0.010396612, 0.0084419865, -...  \n",
       "A1A5B4       [[[0.0075324993, -0.0015358931, -0.0015184287,...  \n",
       "P54368       [[[0.007819155, 0.0008507449, 0.0038550901, 0....  \n",
       "...                                                        ...  \n",
       "Q8TC44       [[[-0.0010542598, -0.0024922702, 0.004882417, ...  \n",
       "P51965       [[[0.0017554004, 0.0024649953, 0.0026940322, -...  \n",
       "Q12891       [[[-0.0035668905, -0.0049079894, 0.002008198, ...  \n",
       "O00198       [[[0.0016759296, -0.0018295981, -0.0023910706,...  \n",
       "P40337       [[[0.00508935, -0.003714442, 0.004217586, -0.0...  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test2_data_with_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
